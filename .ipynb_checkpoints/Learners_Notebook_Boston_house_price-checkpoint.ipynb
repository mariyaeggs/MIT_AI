{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_cJypdzHTQI"
   },
   "source": [
    "# Project Linear Regression: Boston House Price Prediction\n",
    "\n",
    "# **Marks: 30**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ywdg8t8HTQL"
   },
   "source": [
    "Welcome to the project on Linear Regression. We will use the Boston house price data for the exercise.\n",
    "\n",
    "-------------------------------\n",
    "## Problem Statement\n",
    "-------------------------------\n",
    "\n",
    "The problem on hand is to predict the housing prices of a town or a suburb based on the features of the locality provided to us. In the process, we need to identify the most important features in the dataset. We need to employ techniques of data preprocessing and build a linear regression model that predicts the prices for us. \n",
    "\n",
    "----------------------------\n",
    "## Data Information\n",
    "---------------------------\n",
    "\n",
    "Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. Detailed attribute information can be found below-\n",
    "\n",
    "Attribute Information (in order):\n",
    "- **CRIM:**     per capita crime rate by town\n",
    "- **ZN:**       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- **INDUS:**    proportion of non-retail business acres per town\n",
    "- **CHAS:**     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- **NOX:**      nitric oxides concentration (parts per 10 million)\n",
    "- **RM:**       average number of rooms per dwelling\n",
    "- **AGE:**     proportion of owner-occupied units built before 1940\n",
    "- **DIS:**      weighted distances to five Boston employment centers\n",
    "- **RAD:**      index of accessibility to radial highways\n",
    "- **TAX:**      full-value property-tax rate per 10,000 dollars\n",
    "- **PTRATIO:**  pupil-teacher ratio by town\n",
    "- **LSTAT:**    %lower status of the population\n",
    "- **MEDV:**     Median value of owner-occupied homes in 1000 dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pzh5TNLcHTQM"
   },
   "source": [
    "### Let us start by importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JAwzXNJvHTQN"
   },
   "outputs": [],
   "source": [
    "# import libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "\n",
    "# import libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "# settings for seaborn plotting style\n",
    "sns.set(color_codes=True)\n",
    "# settings for seaborn plot sizes\n",
    "#sns.set(rc={'figure.figsize':(5,5)})\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "# import libraries for building linear regression model\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# import library for preparing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import library for data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import library for scientific computing \n",
    "import scipy\n",
    "import scipy.stats as scipy\n",
    "import scipy.stats as norm\n",
    "import scipy.stats as stats\n",
    "# import uniform distribution\n",
    "from scipy.stats import uniform\n",
    "# for latex equations\n",
    "from IPython.display import Math, Latex\n",
    "# for displaying images\n",
    "from IPython.core.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting periscope\n",
      "  Using cached periscope-0.2.4.tar.gz (25 kB)\n",
      "Collecting BeautifulSoup>=3.2.0\n",
      "  Using cached BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/student/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_8f37d0ae5b284a31ac1b9fc501beb6b6/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_8f37d0ae5b284a31ac1b9fc501beb6b6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-pip-egg-info-v3lpouou\n",
      "         cwd: /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_8f37d0ae5b284a31ac1b9fc501beb6b6/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_8f37d0ae5b284a31ac1b9fc501beb6b6/setup.py\", line 3\n",
      "        \"You're trying to run a very old release of Beautiful Soup under Python 3. This will not work.\"<>\"Please use Beautiful Soup 4, available through the pip package 'beautifulsoup4'.\"\n",
      "                                                                                                        ^\n",
      "    SyntaxError: invalid syntax\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/40/f2/6c9f2f3e696ee6a1fb0e4d7850617e224ed2b0b1e872110abffeca2a09d4/BeautifulSoup-3.2.2.tar.gz#sha256=a04169602bff6e3138b1259dbbf491f5a27f9499dea9a8fbafd48843f9d89970 (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached BeautifulSoup-3.2.1.tar.gz (31 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/student/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1d301092132e49edad9b852fd7a97557/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1d301092132e49edad9b852fd7a97557/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-pip-egg-info-2ut6k15w\n",
      "         cwd: /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1d301092132e49edad9b852fd7a97557/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1d301092132e49edad9b852fd7a97557/setup.py\", line 22\n",
      "        print \"Unit tests have failed!\"\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print(\"Unit tests have failed!\")?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/1e/ee/295988deca1a5a7accd783d0dfe14524867e31abb05b6c0eeceee49c759d/BeautifulSoup-3.2.1.tar.gz#sha256=6a8cb4401111e011b579c8c52a51cdab970041cc543814bbd9577a4529fe1cdb (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached BeautifulSoup-3.2.0.tar.gz (31 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/student/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1cf340daf5a74ad4b559541de5c1e814/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1cf340daf5a74ad4b559541de5c1e814/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-pip-egg-info-z7agak_0\n",
      "         cwd: /private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1cf340daf5a74ad4b559541de5c1e814/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/zb/6jslj21n4rl_r356rd2y6nn00000gn/T/pip-install-5h2f_wf_/beautifulsoup_1cf340daf5a74ad4b559541de5c1e814/setup.py\", line 22\n",
      "        print \"Unit tests have failed!\"\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print(\"Unit tests have failed!\")?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/33/fe/15326560884f20d792d3ffc7fe8f639aab88647c9d46509a240d9bfbb6b1/BeautifulSoup-3.2.0.tar.gz#sha256=0dc52d07516c1665c9dd9f0a390a7a054bfb7b147a50b2866fb116b8909dfd37 (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "Collecting periscope\n",
      "  Using cached periscope-0.2.1.tar.gz (25 kB)\n",
      "\u001b[31mERROR: Cannot install periscope==0.2.1 and periscope==0.2.4 because these package versions have conflicting dependencies.\u001b[0m\n",
      "\n",
      "The conflict is caused by:\n",
      "    periscope 0.2.4 depends on BeautifulSoup>=3.2.0\n",
      "    periscope 0.2.1 depends on BeautifulSoup>=3.2.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install periscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7VVqC8nHTQT"
   },
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "zEHB3h_pHTQU",
    "outputId": "87895484-50ac-4e04-ba49-da32f8b78dfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Boston.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynVgcm3SmEaI"
   },
   "source": [
    "**Observations**\n",
    "- The price of the house indicated by the variable MEDV is the target variable.\n",
    "- The other features are the independent variables based on which to predict house price.\n",
    "- On first glance, the per capita crime rate by town CRIM is at its lowest (0.0632%) for \n",
    "areas that have the highest proportion of residential land zoned ZN for lots over 25,000 sq.ft. \n",
    "- The per capita crime rate CRIM by town is at its highest (6.905%) in areas that have a low \n",
    "proportion of non-retail business acres per town INDUS.\n",
    "- There are 4 out of the 5 towns with no proportion of non-retail business acres per town ZN.\n",
    "- In towns with a high proportion of non-retail business acres per town INDUS (7.07%), there is \n",
    "the largest proportion of owner-occupied units built before 1940 AGE. \n",
    "- Nitric oxides concentration (parts per 10 million) NOX, is at its highest in area(s) where \n",
    "there is a high proportion of residential land zoned for lots over 25,000 sq.ft. ZN; this might\n",
    "assume previously agrarian land ready for development and may not be an essential feature in predicting \n",
    "home prices.  \n",
    "- Average number of rooms per dwelling RM should have an affect on the house prices. \n",
    "- There appears to be a correlation between median value of owner-occupied homes in 1000 dollars MEDV at 24.0, \n",
    "and the index of accessibility to radial highways RAD at 1. The lower the accessibility to radial highways, the \n",
    "lower the the median value of owner-occupied homes in 1000 dollars.\n",
    "- For these five features, the highest median value of owner-occupied homes MEDV at 36.2, there appears \n",
    "the highest per capita crime rate by town CRIM at 6.905%.\n",
    "- It might be noteworthy that a very small town will not have a suburb. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PihFetI8HTQd"
   },
   "source": [
    "### Get information about the dataset using the info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGOWxi76HTQd",
    "outputId": "0695ee0a-5e82-49a2-9f7e-9ed8d34e1531",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check the info\n",
    "df.info()\n",
    "\n",
    "#check the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "* There are a total of 506 non-null observations in each of the columns. This indicates that there are no missing values in the data.\n",
    "* There are 13 features that can aid in predicting the price of a home. \n",
    "* Every column in this dataset is numeric in nature.\n",
    "* There are 11 features that help predict housing prices of a town or a suburb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAnFYrfhmEaJ"
   },
   "source": [
    "**Observations**\n",
    "- There are two observations (total 506, we have 504) that do not have data per capita crime rate by town CRIM.\n",
    "- There are only 9 observations for the index of accessibility to radial highways RAD. This might conclude that our data\n",
    "does not comprise of towns or suburban communities that have a high index of accessibility to radial highways RAD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTijRLu82_61"
   },
   "source": [
    "### Let's now check the summary statistics of this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFbX18hKiKo7"
   },
   "source": [
    "#### **Question 1:** Write the code to find the summary statistics and write your observations based on that. (1 Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBhsiAbxHTQg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create numerical columns \n",
    "numerical_columns = ['CRIM','ZN', 'INDUS', 'CHAS',\n",
    "                    'NOX','RM','AGE','DIS','RAD',\n",
    "                    'TAX','PTRATIO','LSTAT','MEDV']\n",
    "numerical_columns\n",
    "\n",
    "#check summary statistics\n",
    "df[numerical_columns].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correlations\n",
    "df_correlations = df.corr()\n",
    "\n",
    "# figure \n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "# mask \n",
    "mask = np.triu(np.ones_like(df_correlations, dtype=np.bool8))\n",
    "\n",
    "# adjust mask and dataframe\n",
    "mask = mask[1:,:-1]\n",
    "correlation = df_correlations.iloc[1:,:-1].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(correlation, mask=mask, annot=True, fmt=\".2f\", cmap='Blues', vmin=-1, vmax=1, cbar_kws={\"shrink\":.8})\n",
    "\n",
    "# yticks \n",
    "# ticks \n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# alternative matrix \n",
    "df_correlations.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The full-value property tax rate per 10,000 dollars TAX in nearly perfect in correlation ~0.910228 with the \n",
    "index of accessibility to five Boston employment centers RAD: this may be suggesting that a property's tax rate\n",
    "is higher near areas where access to employment by way of radial highways is greater.  \n",
    "- Pupil teacher ration by town PTRATION, does not seem to affect per capita crime rate by town CRIM. \n",
    "- It appears that the more weighted distances to Boston employment centers DIS there are, the less \n",
    "per capita crime rate CRIM that town might experience. This negative correlation is not significant however.\n",
    "- As the median value of owner-occupied homes in 1000 dollars increases MEDV, it would be simple to assume that per \n",
    "capita crime rate by town CRIM should also increase; however, this is not the case, there is a negative \n",
    "correlation between MEDV and CRIM, albeit small. \n",
    "- There is a distinct and negative corrlation for proportion of residential land zoned for lots over 25,000 sq.ft ZN \n",
    "and that of INDUS, NOX, AGE, RAD, TAX, LSTAT. It could be possible to hypothize that the higher the proportion of \n",
    "residential land zoned for lots over 25,000 sq. ft., there may be a significant development influx in the town or suburb \n",
    "that contributes to fewer non-retail businesses INDUS, fewer pollutants nitric oxide pollutants permitted in the town/suburb NOX,\n",
    "newer homes that are not originally established in the older part of town but are therefore further away from radial highways RAD, and \n",
    "have a % lower status of the population LSTAT. \n",
    "- There is no explanation evident why the proportion of residential land zoned for lots over 25,000 sq.ft. ZN, appears to be taxed \n",
    "at a lower full-value property-tax rate TAX. \n",
    "- There is a significant correlation between proportion of residential land zoned for lots over 25,000 sq.ft. ZN and \n",
    "the weighted distances to five Boston employment centers DIS. Hypothetically, where employment centers exist, if land zoned for \n",
    "residential has not been entirely utilized, development will occur in an effort to fulfill the need for more housing. \n",
    "- The is a very significant correlation with the proportion of non-retail business acres per town INDUS, and the amount \n",
    "of nitiric oxides concentration NOX. This is possibly suggesting that when land is not developed, it is then used in a way \n",
    "that allows for the increased nitric oxides concentrations NOX. \n",
    "- When a town or suburb has a low proportion of of non-retial business acres per town INDUS, its homes are more proportionally owner-occupied\n",
    "units built before 1940 AGE. \n",
    "- As a town or suburb utilizes its proportion of non-retail business acres INDUS, it experiences an increase in the index of \n",
    "accessibility to radial highways RAD, an increase in the full-value property-tax rate per 10,000 dollars TAX, more pupils to teachers ratio PTRATIO\n",
    "and a increase in %lower status of population LSTAT. These observations suggest that towns or suburbs near urban cores are more populated and \n",
    "have a better access to employment, taxed higher, and see more students attending school(s) in those areas.  \n",
    "- It would seem expected that the nitiric oxicdes concentration (parts per 10 million) NOX, would be higher in areas that have a higher proportion \n",
    "of non-retail business acres per town INDUS. Perhaps these observations are suggesting that greater distances in the town increase travel, which \n",
    "depending on the method of travel can incur more nitric oxide into the atmosphere. \n",
    "- The pupil-teacher ration by town PTRATIO shows hardly any correlation with nitric oxides concentration NOX. This would seem expected. \n",
    "- For average number of rooms per dwelling RM, there is a slight and negative correlation with the other features. There is a significant \n",
    "negative correlation between RM, and specifically, %lower status of population LSTAT, which represents an idea that an increase in that number of rooms per \n",
    "dwelling doesn't necessarily increase the %lower status of a population as could be assumed. \n",
    "- With older homes built before 1940 AGE, there is an increase in nitiric oxide concentration NOX and an increase in the proportion of non-retail business\n",
    "acres per town. This may be implying that older homes are farther apart from each other in a town, than the homes that are newly built.\n",
    "- In older home communities AGE, there is a higher proportion of the population that is part of the lower socioeconomic distinction LSTAT. \n",
    "- The older a home is AGE, the farther it is away from the weighted distances to five Boston employment centers DIS. \n",
    "- Older homes AGE, have a lower median value of owner-occupied homes in 1000 dollars. \n",
    "- From this data, the higher the index of accessibility to radial highways RAD, the higher the proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- The weighted distances to five Boston employment centers, does not significantly affect the median value of owner-occupied homes in 1000 dollars. \n",
    "- The average full-value property-tax rate per 10,000 dollars TAX is higher than the median,\n",
    "which might suggest that some properties pay more per 10,000 dollars than other properties. \n",
    "- There  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJtCqLwhRKpv"
   },
   "source": [
    "Before performing the modeling, it is important to check the univariate distribution of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZF0qJCj6t42"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DccQjNEOmEaL"
   },
   "source": [
    "### Check the distribution of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tz6okxTbmEaL",
    "outputId": "b5de0bcd-3643-4153-f1f5-752875965baf"
   },
   "outputs": [],
   "source": [
    "# check the data distribution \n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.histplot(data=df, x=i, kde = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the cumulative distribution function\n",
    "def CRIM_ECDF_Distribution(df): \n",
    "    #number of data points: n\n",
    "    n=len(df)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x=np.sort(df)\n",
    "\n",
    "    #y-data for the ECDF: y\n",
    "    y=np.arange(1,n+1)/n\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = CRIM_ECDF_Distribution(df[\"CRIM\"])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.set()\n",
    "plt.plot(x,y,marker=\".\",linestyle=\"none\")\n",
    "plt.xlabel(\"CRIM\")\n",
    "plt.ylabel(\"Cumulative Distribution Function\")\n",
    "\n",
    "# compare cumulative distribution funciton to normal distribution\n",
    "random_samples = np.random.normal(np.mean(df[\"CRIM\"]), np.std(df[\"CRIM\"]), size = 1000)\n",
    "\n",
    "# transform data into x, y pairs \n",
    "x_theoretical, y_theoretical = CRIM_ECDF_Distribution(random_samples)\n",
    "\n",
    "plt.plot(x_theoretical, y_theoretical)\n",
    "plt.legend((\"Normal Distribution\", \"Empirical Data\"), loc = \"lower right\")\n",
    "\n",
    "#persicope\n",
    "\n",
    "# test whether the sample data differs from normal distribution\n",
    "print(df[\"CRIM\"])\n",
    "print(stats.normaltest(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r8aVFPbRKpv"
   },
   "source": [
    "**Observations**\n",
    "* **The variables CRIM and ZN are positively skewed.** This suggests that most of the areas have lower crime rates and most residential plots are under the area of 25,000 sq. ft.\n",
    "* **The variable CHAS, with only 2 possible values 0 and 1, follows a binomial distribution**, and the majority of the houses are away from Charles river (CHAS = 0).\n",
    "* The distribution of the variable AGE suggests that many of the owner-occupied houses were built before 1940. \n",
    "* **The variable DIS** (average distances to five Boston employment centers) **has a nearly exponential distribution**, which indicates that most of the houses are closer to these employment centers.\n",
    "* **The variables TAX and RAD have a bimodal distribution.**, indicating that the tax rate is possibly higher for some properties which have a high index of accessibility to radial highways.  \n",
    "* The dependent variable MEDV seems to be slightly right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-_G6u4ZRKpw"
   },
   "source": [
    "As the dependent variable is sightly skewed, we will apply a **log transformation on the 'MEDV' column** and check the distribution of the transformed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvsHuDuvRKpx"
   },
   "outputs": [],
   "source": [
    "df['MEDV_log'] = np.log(df['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "9gf4_f3wRKpx",
    "outputId": "d5abef32-ef6b-44c7-e7a2-18dd5a23ac8f"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='MEDV_log', kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctaaai666Ili"
   },
   "source": [
    "**Observations**\n",
    "* The log-transformed variable (**MEDV_log**) appears to have a **nearly normal distribution without skew**, and hence we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laV5wPBJRKpy"
   },
   "source": [
    "Before creating the linear regression model, it is important to check the bivariate relationship between the variables. Let's check the same using the heatmap and scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvSm7rwE65_B"
   },
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cRRaoo6mEaM"
   },
   "source": [
    "#### Let's check the correlation using the heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNZ_2eRSd2El"
   },
   "source": [
    "### **Question 2** (3 Marks):\n",
    "- **Write the code to plot the correlation heatmap between the variables (1 Mark)**\n",
    "- **Write your observations (2 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGnlhiwGHTQz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(______________,annot=True,fmt='.2f',cmap=cmap ) #write your code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmsjqg4oRAim"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5oXUDmoRKpz"
   },
   "source": [
    "Now, we will visualize the relationship between the pairs of features having significant correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfOeI9ljHTQn"
   },
   "source": [
    "### Visualizing the relationship between the features having significant correlations (> 0.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwsIbVlqd2Et"
   },
   "source": [
    "### **Question 3** (6 Marks):\n",
    "- **Create a scatter plot to visualize the relationship between the features having significant correlations (>0.7) (3 Marks)**\n",
    "- **Write your observations from the plots (3 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Um10uS1zen-7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between NOX and INDUS\n",
    "plt.figure(figsize=(6, 6))\n",
    "#___________________________ #write you code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UztFyhXRAis"
   },
   "source": [
    "**Observations:____**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSvLmh6mmEaN"
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between AGE and NOX\n",
    "plt.figure(figsize=(6, 6))\n",
    "#_____________________________ #Write your code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ognbRRh9RAiw"
   },
   "source": [
    "**Observations:____**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOLrtRekmEaN"
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between DIS and NOX\n",
    "plt.figure(figsize=(6, 6))\n",
    "#_____________________________ #Write your code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqQUKc0RRAiy"
   },
   "source": [
    "**Observations:___**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkhvfnQ0mEaN",
    "outputId": "b1d10228-34be-42ac-f232-ebc945b591a8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between AGE and DIS\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'AGE', y = 'DIS', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyCzhvWqRAi0"
   },
   "source": [
    "**Observations:**\n",
    "* The distance of the houses to the Boston employment centers appears to decrease moderately as the the proportion of the old houses increase in the town. It is possible that the Boston employment centers are located in the established towns where proportion of owner-occupied units built prior to 1940 is comparatively high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWGsd6b6mEaO",
    "outputId": "5755c58f-dab8-40e9-e6f7-d96d8d38309c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between AGE and INDUS\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'AGE', y = 'INDUS', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJONR4x_RAi3"
   },
   "source": [
    "**Observations:**\n",
    "* No trend between the two variables is visible in the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqiKHTqFmEaO",
    "outputId": "05d8dc6e-d124-4ad6-8caf-4a8614a320be",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visulaize the relationship between RAD and TAX\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'RAD', y = 'TAX', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjNld1nnRAi6"
   },
   "source": [
    "**Observations:**\n",
    "* The correlation between RAD and TAX is very high. But, no trend is visible between the two variables. \n",
    "This might be due to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OBx_RTZAYN7"
   },
   "source": [
    "Let's check the correlation after removing the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qTskuPLRKp2",
    "outputId": "b18aad4b-4c23-4d05-c29d-94a5fb6be56a"
   },
   "outputs": [],
   "source": [
    "# remove the data corresponding to high tax rate\n",
    "df1 = df[df['TAX'] < 600]\n",
    "# import the required function\n",
    "from scipy.stats import pearsonr\n",
    "# calculate the correlation\n",
    "print('The correlation between TAX and RAD is', pearsonr(df1['TAX'], df1['RAD'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rib48gHhRKp2"
   },
   "source": [
    "So the high correlation between TAX and RAD is due to the outliers. The tax rate for some properties might be higher due to some other reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5ddxR8JmEaO",
    "outputId": "9fd2ee8b-b184-4408-eab2-104bb33c463b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visualize the relationship between INDUS and TAX\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'INDUS', y = 'TAX', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8laYzUIURKp3"
   },
   "source": [
    "**Observations:**\n",
    "* The tax rate appears to increase with an increase in the proportion of non-retail business acres per town. This might be due to the reason that the variables TAX and INDUS are related with a third variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwoalWG-mEaO",
    "outputId": "b8f7b8a8-a1ca-4024-efa3-1b2d7de9e7b4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visulaize the relationship between RM and MEDV\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'RM', y = 'MEDV', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkZn_JOURKp3"
   },
   "source": [
    "**Observations:**\n",
    "* The price of the house seems to increase as the value of RM increases. This is expected as the price is generally higher for more rooms.\n",
    "\n",
    "* There are a few outliers in a horizontal line as the MEDV value seems to be capped at 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dh3dblT9mEaP",
    "outputId": "ccb46764-3095-4952-9d2a-3582ae6bde41",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatterplot to visulaize the relationship between LSTAT and MEDV\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x = 'LSTAT', y = 'MEDV', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgcUFLZgmEaP"
   },
   "source": [
    "**Observations:**\n",
    "* The price of the house tends to decrease with an increase in LSTAT. This is also possible as the house price is lower in areas where lower status people live.\n",
    "* There are few outliers and the data seems to be capped at 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2Gowz5GRKp4"
   },
   "source": [
    "We have seen that the variables LSTAT and RM have a linear relationship with the dependent variable MEDV. Also, there are significant relationships among a few independent variables, which is not desirable for a linear regression model. Let's first split the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdPzLNVRHTQ2"
   },
   "source": [
    "### Split the dataset\n",
    "Let's split the data into the dependent and independent variables and further split it into train and test set in a ratio of 70:30 for train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beebRRkvHTQ3"
   },
   "outputs": [],
   "source": [
    "# separate the dependent and independent variable\n",
    "Y = df['MEDV_log']\n",
    "X = df.drop(columns = {'MEDV', 'MEDV_log'})\n",
    "\n",
    "# add the intercept term\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRFWKGdpHTQ5"
   },
   "outputs": [],
   "source": [
    "# splitting the data in 70:30 ratio of train to test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30 , random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGhbeT42mEaQ"
   },
   "source": [
    "Next, we will check the multicollinearity in the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35V8i1tVRKp5"
   },
   "source": [
    "### Check for Multicollinearity\n",
    "\n",
    "We will use the Variance Inflation Factor (VIF), to check if there is multicollinearity in the data.\n",
    "\n",
    "Features having a VIF score > 5 will be dropped/treated till all the features have a VIF score < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy-mv-XrmEaU",
    "outputId": "13351efd-3eb5-4353-e20f-89dd0b665b86",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# function to check VIF\n",
    "def checking_vif(train):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = train.columns\n",
    "\n",
    "    # calculating VIF for each feature\n",
    "    vif[\"VIF\"] = [\n",
    "        variance_inflation_factor(train.values, i) for i in range(len(train.columns))\n",
    "    ]\n",
    "    return vif\n",
    "\n",
    "\n",
    "print(checking_vif(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oPR2ihWmEaU"
   },
   "source": [
    "**Observations:**\n",
    "* There are two variables with a high VIF - RAD and TAX. Let's remove TAX as it has the highest VIF values and check the multicollinearity again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vXnOaY2kWG_"
   },
   "source": [
    "#### **Question 4:** Drop the column 'TAX' from the training data and check if multicollinearity is removed? (1 Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD8YQ9GlRKp5"
   },
   "outputs": [],
   "source": [
    "# create the model after dropping TAX\n",
    "X_train = #Write your code here\n",
    "\n",
    "# check for VIF\n",
    "print(checking_vif(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPxryqE7RKp6"
   },
   "source": [
    "Now, we will create the linear regression model as the VIF is less than 5 for all the independent variables, and we can assume that multicollinearity has been removed between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqm-fpjUkrtt"
   },
   "source": [
    "#### **Question 5:** Write the code to create the linear regression model and print the model summary. Write your observations from the model. (3 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwDjEfcBjyV7"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model1 = #write your code here\n",
    "\n",
    "# get the model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yde7rQQWRAjU"
   },
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI70ISxilFbI"
   },
   "source": [
    "#### **Question 6:** Drop insignificant variables from the above model and create the regression model again. (2 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QIZkgXLmEaU"
   },
   "source": [
    "### Examining the significance of the model\n",
    "\n",
    "It is not enough to fit a multiple regression model to the data, it is necessary to check whether all the regression coefficients are significant or not. Significance here means whether the population regression parameters are significantly different from zero. \n",
    "\n",
    "From the above it may be noted that the regression coefficients corresponding to ZN, AGE, and INDUS are not statistically significant at level α = 0.05. In other words, the regression coefficients corresponding to these three are not significantly different from 0 in the population. Hence, we will eliminate the three features and create a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwsYfoPtRKp7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the model after dropping columns 'MEDV', 'MEDV_log', 'TAX', 'ZN', 'AGE', 'INDUS' from df dataframe\n",
    "Y = df['MEDV_log']\n",
    "X = df.drop(_____________________________) #write your code here\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#splitting the data in 70:30 ratio of train to test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30 , random_state=1)\n",
    "\n",
    "# create the model\n",
    "model2 = __________________________ #write your code here\n",
    "# get the model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5itYQa0zwtPa"
   },
   "source": [
    "**Observations:**\n",
    "* We can see that the **R-squared value has decreased by 0.002**, since we have removed variables from the model, whereas the **adjusted R-squared value has increased by 0.001**, since we removed statistically insignificant variables only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnntdbE8RKp8"
   },
   "source": [
    "Now, we will check the linear regression assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRxnpWg3mEaR"
   },
   "source": [
    "### Check the below linear regression assumptions\n",
    "\n",
    "1. **Mean of residuals should be 0**\n",
    "2. **No Heteroscedasticity**\n",
    "3. **Linearity of variables**\n",
    "4. **Normality of error terms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FWIklI2libx"
   },
   "source": [
    "#### **Question 7:** Write the code to check the above linear regression assumptions and provide insights. (4 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QAPpLhrmEaV"
   },
   "source": [
    "#### Check for mean residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeCX4j8vmEaV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals = \n",
    "\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvYEVyfQRAjh"
   },
   "source": [
    "**Observations:____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df7sEIL0mEaW"
   },
   "source": [
    "#### Check for homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StSElLVFRKp9"
   },
   "source": [
    "* Homoscedasticity - If the residuals are symmetrically distributed across the regression line, then the data is said to homoscedastic.\n",
    "\n",
    "* Heteroscedasticity - If the residuals are not symmetrically distributed across the regression line, then the data is said to be heteroscedastic. In this case, the residuals can form a funnel shape or any other non-symmetrical shape.\n",
    "\n",
    "* We'll use `Goldfeldquandt Test` to test the following hypothesis with alpha = 0.05:\n",
    "\n",
    "    - Null hypothesis: Residuals are homoscedastic\n",
    "    - Alternate hypothesis: Residuals have heteroscedastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4as-Efdd2Fn"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpFfPIdkmEaW"
   },
   "outputs": [],
   "source": [
    "name = [\"F statistic\", \"p-value\"]\n",
    "test = ____________________________\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TPhzwu6RAjm"
   },
   "source": [
    "**Observations:____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzbnPofwmEaX"
   },
   "source": [
    "#### Linearity of variables\n",
    "\n",
    "It states that the predictor variables must have a linear relation with the dependent variable.\n",
    "\n",
    "To test the assumption, we'll plot residuals and fitted values on a plot and ensure that residuals do not form a strong pattern. They should be randomly and uniformly scattered on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "UxjY8jyKmEaX",
    "outputId": "6226e309-cb8e-44b5-d961-bb6154949949",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicted values\n",
    "fitted = model2.fittedvalues\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.residplot(x = ______ y = ________, color=\"lightblue\", lowess=True) #write your code here\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residual PLOT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYWMZchHmEaX"
   },
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1UAjPqMmEaX"
   },
   "source": [
    "#### Normality of error terms\n",
    "The residuals should be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFHf71ewmEaX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram of residuals\n",
    "#write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "8aVhzXhEmEaY",
    "outputId": "4f867523-0e7c-410b-804b-158448e04367",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot q-q plot of residuals\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot(residuals, dist=\"norm\", plot=pylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPo9UIlgRKp-"
   },
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8q-edLJmEaR"
   },
   "source": [
    "### Check the performance of the model on the train and test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gib4S6PRmS-y"
   },
   "source": [
    "#### **Question 8:** Write your observations by comparing model performance of train and test dataset (2 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5_l2YusmEaR",
    "outputId": "32951568-7fc9-4e6f-c6ea-06a7d46f8c66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((targets - predictions) ** 2).mean())\n",
    "\n",
    "\n",
    "# MAPE\n",
    "def mape(predictions, targets):\n",
    "    return np.mean(np.abs((targets - predictions)) / targets) * 100\n",
    "\n",
    "\n",
    "# MAE\n",
    "def mae(predictions, targets):\n",
    "    return np.mean(np.abs((targets - predictions)))\n",
    "\n",
    "\n",
    "# Model Performance on test and train data\n",
    "def model_pref(olsmodel, x_train, x_test):\n",
    "\n",
    "    # In-sample Prediction\n",
    "    y_pred_train = olsmodel.predict(x_train)\n",
    "    y_observed_train = y_train\n",
    "\n",
    "    # Prediction on test data\n",
    "    y_pred_test = olsmodel.predict(x_test)\n",
    "    y_observed_test = y_test\n",
    "\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Data\": [\"Train\", \"Test\"],\n",
    "                \"RMSE\": [\n",
    "                    rmse(y_pred_train, y_observed_train),\n",
    "                    rmse(y_pred_test, y_observed_test),\n",
    "                ],\n",
    "                \"MAE\": [\n",
    "                    mae(y_pred_train, y_observed_train),\n",
    "                    mae(y_pred_test, y_observed_test),\n",
    "                ],\n",
    "                \"MAPE\": [\n",
    "                    mape(y_pred_train, y_observed_train),\n",
    "                    mape(y_pred_test, y_observed_test),\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Checking model performance\n",
    "model_pref(model2, X_train, X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf9MNVkFRAjy"
   },
   "source": [
    "**Observations:____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WexM8Ae2RKp_"
   },
   "source": [
    "#### Apply cross validation to improve the model and evaluate it using different evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELl7h2K1mzwB"
   },
   "source": [
    "#### **Question 9:** Apply the cross validation technique to improve the model and evaluate it using different evaluation metrics. (1 Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxh0bcTbRKp_"
   },
   "outputs": [],
   "source": [
    "# import the required function\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build the regression model and cross-validate\n",
    "linearregression = LinearRegression()                                    \n",
    "\n",
    "cv_Score11 = #write your code here\n",
    "cv_Score12 = #write your code here                                \n",
    "\n",
    "\n",
    "print(\"RSquared: %0.3f (+/- %0.3f)\" % (cv_Score11.mean(), cv_Score11.std() * 2))\n",
    "print(\"Mean Squared Error: %0.3f (+/- %0.3f)\" % (-1*cv_Score12.mean(), cv_Score12.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGlElmnMRKp_"
   },
   "source": [
    "**Observations**\n",
    "- The R-squared on the cross validation is 0.729, whereas on the training dataset it was 0.769\n",
    "- And the MSE on cross validation is 0.041, whereas on the training dataset it was 0.038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWlw3A04RKp_"
   },
   "source": [
    "We may want to reiterate the model building process again with new features or better feature engineering to increase the R-squared and decrease the MSE on cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDC6O874m9_T"
   },
   "source": [
    "#### **Question 10:** Get model Coefficients in a pandas dataframe with column 'Feature' having all the features and column 'Coefs' with all the corresponding Coefs. Write the regression equation. (2 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqgvS0SXHTRW",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coef = #write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWh3qZDlHTRY",
    "outputId": "30d49dad-b88b-4a70-c783-65f3c4d7f0af"
   },
   "outputs": [],
   "source": [
    "# Let us write the equation of the fit\n",
    "Equation = \"log (Price) =\"\n",
    "print(Equation, end='\\t')\n",
    "for i in range(len(coef)):\n",
    "    print('(', coef[i], ') * ', coef.index[i], '+', end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KNywQaDRKqA"
   },
   "source": [
    "#### **Question 11:** Write the conclusions and business recommendations derived from the model. (5 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtKmJZYxRAj-"
   },
   "source": [
    "Write Conclusions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hvyj9LZNR2PY"
   },
   "source": [
    "Write Recommendations here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Pzh5TNLcHTQM",
    "J7VVqC8nHTQT",
    "PihFetI8HTQd"
   ],
   "name": "Learners_Notebook_Boston_house_price.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
